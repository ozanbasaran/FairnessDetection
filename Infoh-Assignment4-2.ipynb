{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subgroups that MDSS identifies:\n",
    "- Priviliged groups: `Non-caucasian`, `less than 25`, `Male`\n",
    "- Unpriviliged groups:  `Non-caucasian`, `Female`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will be comparing the bias between:\n",
    "\n",
    "1. Priviliged by MDSS vs. Opposite in one attribute:\n",
    "- Non-caucasian, less than 25, Male vs. Non-caucasian, less than 25, Female\n",
    "- Non-caucasian, less than 25, Male vs. Caucasian, less than 25, Male\n",
    "1. Unpriviliged by MDSS vs. Opposite in one attribute:\n",
    "- Non-caucasian, Female vs. Caucasian, Female\n",
    "- Non-caucasian, Female vs. Non-caucasian, Male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, MDSSClassificationMetric\n",
    "from aif360.detectors import bias_scan\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_compas\n",
    "from aif360.datasets import StandardDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cocausian_less25_male = [{'race': 0, 'age_cat': 0, 'sex':0}]\n",
    "non_cocausian_less25_female = [{'race': 0, 'age_cat': 0, 'sex': 1}]\n",
    "cocausian_less25_male = [{'race': 1, 'age_cat': 0, 'sex': 0}]\n",
    "\n",
    "non_cocausian_female = [{'race': 0, 'sex': 1}]\n",
    "cocausian_female = [{'race': 1, 'sex': 1}]\n",
    "non_cocausian_male = [{'race': 0, 'sex': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-caucasian, less than 25, Male And Non-caucasian, less than 25, Female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = load_preproc_data_compas()\n",
    "dataset_orig_df = pd.DataFrame(dataset_orig.features, columns=dataset_orig.feature_names)\n",
    "\n",
    "age_cat = np.argmax(dataset_orig_df[['age_cat=Less than 25', 'age_cat=25 to 45',\n",
    "                                     'age_cat=Greater than 45']].values, axis=1).reshape(-1, 1)\n",
    "priors_count = np.argmax(dataset_orig_df[['priors_count=0', 'priors_count=1 to 3',\n",
    "                                          'priors_count=More than 3']].values, axis=1).reshape(-1, 1)\n",
    "c_charge_degree = np.argmax(dataset_orig_df[['c_charge_degree=M', 'c_charge_degree=F']].values, axis=1).reshape(-1, 1)\n",
    "\n",
    "features = np.concatenate((dataset_orig_df[['sex', 'race']].values, age_cat, priors_count,\n",
    "                           c_charge_degree, dataset_orig.labels), axis=1)\n",
    "feature_names = ['sex', 'race', 'age_cat', 'priors_count', 'c_charge_degree']\n",
    "\n",
    "df = pd.DataFrame(features, columns=feature_names + ['two_year_recid'])\n",
    "\n",
    "dataset = StandardDataset(df, label_name='two_year_recid', favorable_classes=[0],\n",
    "                 protected_attribute_names=['sex', 'race', 'age_cat'],\n",
    "                 privileged_classes=[[1], [1], [1]],\n",
    "                 instance_weights_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.148845\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.328246\n"
     ]
    }
   ],
   "source": [
    "dataset_orig_train, dataset_orig_test = dataset.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "metric_train = BinaryLabelDatasetMetric(dataset_orig_train,\n",
    "                             unprivileged_groups=non_cocausian_less25_female,\n",
    "                             privileged_groups=non_cocausian_less25_male)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train.mean_difference())\n",
    "metric_test = BinaryLabelDatasetMetric(dataset_orig_test,\n",
    "                             unprivileged_groups=non_cocausian_less25_female,\n",
    "                             privileged_groups=non_cocausian_less25_male)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs', C=1.0, penalty='l2', random_state=0)\n",
    "clf.fit(dataset_orig_train.features, dataset_orig_train.labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bias_test_prob = clf.predict_proba(dataset_orig_test.features)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>observed</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.552951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.584908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  race  age_cat  priors_count  c_charge_degree  observed  probabilities\n",
       "0  1.0   1.0      2.0           2.0              1.0       1.0       0.552951\n",
       "1  1.0   0.0      1.0           0.0              1.0       0.0       0.740959\n",
       "2  0.0   1.0      0.0           1.0              1.0       0.0       0.374728\n",
       "3  0.0   0.0      2.0           2.0              1.0       1.0       0.444487\n",
       "4  0.0   1.0      1.0           1.0              0.0       1.0       0.584908"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset_orig_test.features, columns=dataset_orig_test.feature_names)\n",
    "df['observed'] = pd.Series(dataset_orig_test.labels.flatten(), index=df.index)\n",
    "df['probabilities'] = pd.Series(dataset_bias_test_prob, index=df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bias_test = dataset_orig_test.copy()\n",
    "dataset_bias_test.scores = dataset_bias_test_prob\n",
    "dataset_bias_test.labels = dataset_orig_test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dataset_bias_test.convert_to_dataframe()[0]\n",
    "test_df['model_not_recid'] = dataset_bias_test.scores.flatten()\n",
    "test_df['observed_not_recid'] = 1 - test_df['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_not_recid       0.426994\n",
       "observed_not_recid    0.322917\n",
       "dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-Caucasian, less than 25, male prediction vs observation \n",
    "test_df[(test_df['sex'] == 0) & (test_df['race'] == 0) & (test_df['age_cat'] == 0)][['model_not_recid','observed_not_recid']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_not_recid       0.537471\n",
       "observed_not_recid    0.651163\n",
       "dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-Caucasian, less than 25, female prediction vs observation \n",
    "test_df[(test_df['sex'] == 1) & (test_df['race'] == 0) & (test_df['age_cat'] == 0)][['model_not_recid','observed_not_recid']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "mdss_classified_1 = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=non_cocausian_less25_male,\n",
    "                                           privileged_groups=non_cocausian_less25_female)\n",
    "group1_unprivileged_score = mdss_classified_1.score_groups(privileged=False)\n",
    "print(group1_unprivileged_score)\n",
    "group1_privileged_score = mdss_classified_1.score_groups(privileged=True)\n",
    "print(group1_privileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results (0.0 for both scores), there is no evidence that `Non-caucasian, less than 25, male` is unpriviliged, and also no evidence that `Non-caucasian, less than 25, female` is priviliged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2296\n",
      "4.6526\n"
     ]
    }
   ],
   "source": [
    "mdss_classified_2 = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=non_cocausian_less25_female,\n",
    "                                           privileged_groups=non_cocausian_less25_male)\n",
    "group1_unprivileged_score = mdss_classified_2.score_groups(privileged=False)\n",
    "print(group1_unprivileged_score)\n",
    "group1_privileged_score = mdss_classified_2.score_groups(privileged=True)\n",
    "print(group1_privileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, there is evidence that `Non-caucasian, less than 25, male` is priviliged, and also evidence that `Non-caucasian, less than 25, female` is unpriviliged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-caucasian, less than 25, Male And Caucasian, less than 25, Male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.095904\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.145438\n"
     ]
    }
   ],
   "source": [
    "dataset_orig_train, dataset_orig_test = dataset.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "metric_train = BinaryLabelDatasetMetric(dataset_orig_train,\n",
    "                             unprivileged_groups=cocausian_less25_male,\n",
    "                             privileged_groups=non_cocausian_less25_male)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train.mean_difference())\n",
    "metric_test = BinaryLabelDatasetMetric(dataset_orig_test,\n",
    "                             unprivileged_groups=cocausian_less25_male,\n",
    "                             privileged_groups=non_cocausian_less25_male)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_not_recid       0.426994\n",
       "observed_not_recid    0.322917\n",
       "dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-Caucasian, less than 25, male prediction vs observation \n",
    "test_df[(test_df['sex'] == 0) & (test_df['race'] == 0) & (test_df['age_cat'] == 0)][['model_not_recid','observed_not_recid']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_not_recid       0.462076\n",
       "observed_not_recid    0.468354\n",
       "dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caucasian, less than 25, male prediction vs observation \n",
    "test_df[(test_df['sex'] == 0) & (test_df['race'] == 1) & (test_df['age_cat'] == 0)][['model_not_recid','observed_not_recid']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "mdss_classified_2 = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=non_cocausian_less25_male,\n",
    "                                           privileged_groups=cocausian_less25_male)\n",
    "group1_unprivileged_score = mdss_classified_2.score_groups(privileged=False)\n",
    "print(group1_unprivileged_score)\n",
    "group1_privileged_score = mdss_classified_2.score_groups(privileged=True)\n",
    "print(group1_privileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results (0.0 for both scores), there is no evidence that `Non-caucasian, less than 25, male` is unpriviliged, and also no evidence that `Caucasian, less than 25, male` is priviliged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0067\n",
      "4.6526\n"
     ]
    }
   ],
   "source": [
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=cocausian_less25_male,\n",
    "                                           privileged_groups=non_cocausian_less25_male)\n",
    "group1_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group1_unprivileged_score)\n",
    "group1_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group1_privileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, there is evidence that `Non-caucasian, less than 25, male` is priviliged. As for `Caucasian, less than 25, male` the score is very low (close to 0) which doesn't reflect a high bias against this group, it is not unpriviliged in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-caucasian, Female And Non-caucasian, Male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.164657\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.232482\n"
     ]
    }
   ],
   "source": [
    "dataset_orig_train, dataset_orig_test = dataset.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "metric_train = BinaryLabelDatasetMetric(dataset_orig_train,\n",
    "                             unprivileged_groups=non_cocausian_female,\n",
    "                             privileged_groups=non_cocausian_male)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train.mean_difference())\n",
    "metric_test = BinaryLabelDatasetMetric(dataset_orig_test,\n",
    "                             unprivileged_groups=non_cocausian_female,\n",
    "                             privileged_groups=non_cocausian_male)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_not_recid       0.563478\n",
       "observed_not_recid    0.668639\n",
       "dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-Caucasian, female prediction vs observation \n",
    "test_df[(test_df['sex'] == 1) & (test_df['race'] == 0)][['model_not_recid','observed_not_recid']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_not_recid       0.469250\n",
       "observed_not_recid    0.436157\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-caucasian, male prediction vs observation \n",
    "test_df[(test_df['sex'] == 0) & (test_df['race'] == 0)][['model_not_recid','observed_not_recid']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=non_cocausian_male,\n",
    "                                           privileged_groups=non_cocausian_female)\n",
    "group1_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group1_unprivileged_score)\n",
    "group1_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group1_privileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results (0.0 for both scores), there is no evidence that `Non-caucasian, male` is unpriviliged, and also no evidence that `Non-caucasian, female` is priviliged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3036\n",
      "1.9281\n"
     ]
    }
   ],
   "source": [
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=non_cocausian_female,\n",
    "                                           privileged_groups=non_cocausian_male)\n",
    "group1_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group1_unprivileged_score)\n",
    "group1_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group1_privileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, there is evidence that `Non-caucasian, female` is priviliged. And also evidence that `Non-caucasian, male` is unpriviliged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-caucasian, Female And Caucasian, Female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.035810\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.025282\n"
     ]
    }
   ],
   "source": [
    "dataset_orig_train, dataset_orig_test = dataset.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "metric_train = BinaryLabelDatasetMetric(dataset_orig_train,\n",
    "                             unprivileged_groups=non_cocausian_female,\n",
    "                             privileged_groups=cocausian_female)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train.mean_difference())\n",
    "metric_test = BinaryLabelDatasetMetric(dataset_orig_test,\n",
    "                             unprivileged_groups=non_cocausian_female,\n",
    "                             privileged_groups=cocausian_female)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_not_recid       0.563478\n",
       "observed_not_recid    0.668639\n",
       "dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-Caucasian, female prediction vs observation \n",
    "test_df[(test_df['sex'] == 1) & (test_df['race'] == 0)][['model_not_recid','observed_not_recid']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_not_recid       0.681477\n",
       "observed_not_recid    0.643357\n",
       "dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caucasian, female prediction vs observation \n",
    "test_df[(test_df['sex'] == 1) & (test_df['race'] == 1)][['model_not_recid','observed_not_recid']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=cocausian_female,\n",
    "                                           privileged_groups=non_cocausian_female)\n",
    "group1_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group1_unprivileged_score)\n",
    "group1_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group1_privileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results (0.0 for both scores), there is no evidence that `Caucasian, Female` is unpriviliged, and also no evidence that `Non-caucasian, Female` is priviliged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3036\n",
      "0.5258\n"
     ]
    }
   ],
   "source": [
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=non_cocausian_female,\n",
    "                                           privileged_groups=cocausian_female)\n",
    "group1_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group1_unprivileged_score)\n",
    "group1_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group1_privileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, there is evidence that `Caucasian, female` is priviliged. And there is no evidence that `Non-caucasian, Female` is unpriviliged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
